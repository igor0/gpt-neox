{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cfd86d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ruamel.yaml\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 KB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.6-cp38-cp38-manylinux1_x86_64.whl (570 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.4/570.4 KB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
      "Successfully installed ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install ruamel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02c68599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "#torch.load(\"\")\n",
    "\n",
    "def go(layers):\n",
    "    for f in glob.glob(\"/mnt/ssd-1/igor/gpt-neox/models/dense_large.logit_lens.{}/*/*.pt\".format(layers)):\n",
    "        ch = torch.load(f, map_location=\"cpu\")\n",
    "        if 'args' in ch:\n",
    "            del ch['optimizer']\n",
    "            ch['args']['num_layers'] = layers\n",
    "            os.rename(f, f + \".args_orig\")\n",
    "            torch.save(ch, f)\n",
    "        del ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    go(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in range(25):\n",
    "    for f in glob.glob(\"/mnt/ssd-1/igor/gpt-neox/models/dense_medium.{}/*/*.pt\".format(layers)):\n",
    "        ch = torch.load(f)\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a28201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from ruamel.yaml import YAML\n",
    "\n",
    "inp = \"\"\"\\\n",
    "{\n",
    "   # parallelism settings ( you will want to change these based on your cluster setup, ideally scheduling pipeline stages\n",
    "   # across the node boundaries )\n",
    "   \"pipe-parallel-size\": 1,\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "yaml = YAML()\n",
    "code = yaml.load(inp)\n",
    "yaml.dump(code, sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "file_name = '/mnt/ssd-1/igor/gpt-neox/models/dense_medium/configs/config.yml'\n",
    "with open(file_name) as conf_file:\n",
    "    conf = yaml.load(conf_file, Loader=yaml.FullLoader)\n",
    "\n",
    "print(conf['num-layers'])\n",
    "conf['num-layers'] = 17\n",
    "conf['load'] = \"mypath\"\n",
    "conf['save'] = \"mypath\"\n",
    "\n",
    "with open('/tmp/test.yml', 'w') as f:\n",
    "    yaml.dump(conf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e820a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming micpie-0-0\n",
      "Renaming micpie-0-0\n",
      "Renaming micpie-0-0\n",
      "Stopping on dense_small.in_linear_all.9\n"
     ]
    }
   ],
   "source": [
    "# Rename wandb runs\n",
    "\n",
    "import wandb\n",
    "import json\n",
    "import os\n",
    "\n",
    "api = wandb.Api()\n",
    "for run in api.runs(\"igoro/neox\"):\n",
    "    if run.name != \"micpie-0-0\":\n",
    "        print(\"Stopping on\", run.name)\n",
    "        break\n",
    "\n",
    "    j = json.loads(run.json_config)\n",
    "    if \"load\" in j and \"value\" in j[\"load\"]:\n",
    "        new_name = os.path.basename(j[\"load\"][\"value\"])\n",
    "    else:\n",
    "        print(\"WARNING: Skipping\", run)\n",
    "        continue\n",
    "    \n",
    "    print(\"Renaming\", run.name)\n",
    "    run.name = new_name\n",
    "    run.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfab1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def show(x, prefix = \"\", path = \"\"):\n",
    "    if type(x) is dict or type(x) is OrderedDict:\n",
    "        print(prefix, path)\n",
    "        for key in x.keys():\n",
    "            show(x[key], prefix + \"  \", str(key))\n",
    "    elif type(x) is torch.Tensor:\n",
    "        print(prefix, path, x.shape, x.dtype)\n",
    "    elif type(x) is list:\n",
    "        print(prefix, path)\n",
    "        for i in range(len(x)):\n",
    "            show(x[i], prefix + \"  \", \"[{}]\".format(i))\n",
    "    else:\n",
    "        print(prefix, path, type(x))\n",
    "\n",
    "def go(model, checkpoint):\n",
    "    for f in glob.glob(\"/mnt/ssd-1/igor/gpt-neox/models/{}/{}/*.pt\".format(model, checkpoint)):\n",
    "        ch = torch.load(f, map_location=\"cpu\")\n",
    "        print(\"----\", f)\n",
    "        if 'optimizer' in ch:\n",
    "            #print(f, ch['optimizer'][\"optimizer_state_dict\"].keys())\n",
    "            show(ch)\n",
    "\n",
    "\n",
    "def load(model, checkpoint):\n",
    "    for f in glob.glob(\"/mnt/ssd-1/igor/gpt-neox/models/{}/{}/mp_*.pt\".format(model, checkpoint)):\n",
    "        ch = torch.load(f, map_location=\"cpu\")\n",
    "        return ch\n",
    "#go(\"dense_small.final_linear.7\", \"global_step10000\")\n",
    "#go(\"dense_small.logit_lens.7\", \"global_step485000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(c1)\n",
    "#print(c2)\n",
    "#c2[\"optimizer\"][\"scale_window\"] = c1[\"optimizer\"][\"scale_window\"]\n",
    "\n",
    "\n",
    "c1 = load(\"dense_small.final_linear.7\", \"global_step10000\")\n",
    "c2 = load(\"dense_small.logit_lens.7\", \"global_step485000\")\n",
    "#c2[\"optimizer\"][\"fp32_groups_flat\"] = []\n",
    "torch.save(c2, \"/mnt/ssd-1/igor/gpt-neox/models/dense_small.final_linear.7_exp/baseline/mp_rank_00_model_states.pt\")\n",
    "\n",
    "#shutil.copy(\"/mnt/ssd-1/igor/gpt-neox/models/dense_small.final_linear.7/baseline/mp_rank_00_model_states.pt\", \"/mnt/ssd-1/igor/gpt-neox/models/dense_small.final_linear.7_exp/baseline/\")\n",
    "#shutil.copy(\"/mnt/ssd-1/igor/gpt-neox/models/dense_small.logit_lens.7/global_step485000/mp_rank_00_model_states.pt\", \"/mnt/ssd-1/igor/gpt-neox/models/dense_small.final_linear.7_exp/baseline/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = load(\"dense_small.final_linear.7\", \"global_step10000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e693f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2786ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = torch.load(\"/mnt/ssd-1/igor/gpt-neox/models/dense_small/global_step485000/mp_rank_00_model_states.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e741fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c40b24d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/*.pt\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_00-model_00-model_states.pt\n",
      " \n",
      "   word_embeddings.weight torch.Size([50304, 1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_02-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_03-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_04-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_05-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_06-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_07-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_08-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_09-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_10-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_11-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_12-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_13-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_14-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_15-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_16-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_17-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_18-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_19-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_20-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_21-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_22-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_23-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_24-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_25-model_00-model_states.pt\n",
      " \n",
      "   input_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   input_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   attention.query_key_value.weight torch.Size([3072, 1024]) torch.float16\n",
      "   attention.query_key_value.bias torch.Size([3072]) torch.float16\n",
      "   attention.rotary_emb.inv_freq torch.Size([64]) torch.float16\n",
      "   attention.dense.weight torch.Size([1024, 1024]) torch.float16\n",
      "   attention.dense.bias torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.weight torch.Size([1024]) torch.float16\n",
      "   post_attention_layernorm.bias torch.Size([1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.weight torch.Size([4096, 1024]) torch.float16\n",
      "   mlp.dense_h_to_4h.bias torch.Size([4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.weight torch.Size([1024, 4096]) torch.float16\n",
      "   mlp.dense_4h_to_h.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_27-model_00-model_states.pt\n",
      " \n",
      "   norm.weight torch.Size([1024]) torch.float16\n",
      "   norm.bias torch.Size([1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/layer_28-model_00-model_states.pt\n",
      " \n",
      "   final_linear.weight torch.Size([50304, 1024]) torch.float16\n",
      "---- /mnt/ssd-1/igor/gpt-neox/models/dense_medium/global_step250000/mp_rank_00_model_states.pt\n",
      " \n",
      "   module <class 'NoneType'>\n",
      "   optimizer\n",
      "     dynamic_loss_scale <class 'bool'>\n",
      "     cur_scale <class 'float'>\n",
      "     cur_iter <class 'int'>\n",
      "     last_overflow_iter <class 'int'>\n",
      "     scale_factor <class 'int'>\n",
      "     scale_window <class 'int'>\n",
      "     optimizer_state_dict\n",
      "       state\n",
      "         0\n",
      "           exp_avg torch.Size([405012480]) torch.float32\n",
      "           exp_avg_sq torch.Size([405012480]) torch.float32\n",
      "         1\n",
      "           exp_avg torch.Size([321536]) torch.float32\n",
      "           exp_avg_sq torch.Size([321536]) torch.float32\n",
      "       param_groups\n",
      "         [0]\n",
      "           lr <class 'float'>\n",
      "           bias_correction <class 'bool'>\n",
      "           betas\n",
      "             [0] <class 'float'>\n",
      "             [1] <class 'float'>\n",
      "           eps <class 'float'>\n",
      "           weight_decay <class 'float'>\n",
      "           step <class 'int'>\n",
      "           params\n",
      "             [0] <class 'int'>\n",
      "         [1]\n",
      "           weight_decay <class 'float'>\n",
      "           lr <class 'float'>\n",
      "           bias_correction <class 'bool'>\n",
      "           betas\n",
      "             [0] <class 'float'>\n",
      "             [1] <class 'float'>\n",
      "           eps <class 'float'>\n",
      "           step <class 'int'>\n",
      "           params\n",
      "             [0] <class 'int'>\n",
      "     fp32_groups_flat\n",
      "       [0] torch.Size([405012480]) torch.float32\n",
      "       [1] torch.Size([321536]) torch.float32\n",
      "     clip_grad <class 'float'>\n",
      "   lr_scheduler\n",
      "     start_lr <class 'float'>\n",
      "     warmup_iter <class 'float'>\n",
      "     num_iters <class 'int'>\n",
      "     decay_style <class 'str'>\n",
      "     end_iter <class 'int'>\n",
      "     min_lr <class 'float'>\n",
      "   csr_tensor_module_names <class 'set'>\n",
      "   skipped_steps <class 'int'>\n",
      "   global_steps <class 'int'>\n",
      "   global_samples <class 'int'>\n",
      "   dp_world_size <class 'int'>\n",
      "   mp_world_size <class 'int'>\n",
      "   iteration <class 'int'>\n",
      "   args\n",
      "     num_layers <class 'int'>\n",
      "     hidden_size <class 'int'>\n",
      "     num_attention_heads <class 'int'>\n",
      "     max_position_embeddings <class 'int'>\n",
      "     make_vocab_size_divisible_by <class 'int'>\n",
      "     padded_vocab_size <class 'int'>\n",
      "     tokenizer_type <class 'str'>\n",
      "     model_parallel_size <class 'int'>\n",
      "   random_rng_state <class 'tuple'>\n",
      "   np_rng_state <class 'tuple'>\n",
      "   torch_rng_state torch.Size([5056]) torch.uint8\n",
      "   cuda_rng_state torch.Size([816]) torch.uint8\n",
      "   rng_tracker_states\n",
      "     model-parallel-rng torch.Size([816]) torch.uint8\n"
     ]
    }
   ],
   "source": [
    "model = \"dense_medium\"\n",
    "checkpoint = \"global_step250000\"\n",
    "print(\"/mnt/ssd-1/igor/gpt-neox/models/{}/{}/*.pt\".format(model, checkpoint))\n",
    "for f in sorted(glob.glob(\"/mnt/ssd-1/igor/gpt-neox/models/{}/{}/*.pt\".format(model, checkpoint))):\n",
    "    ch = torch.load(f, map_location=\"cpu\")\n",
    "    print(\"----\", f)\n",
    "    show(ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
